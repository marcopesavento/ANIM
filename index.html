<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="marco_pesavento">
  <title>ANIM</title>
  
  <!-- CSS  -->
  <link href="./style/materialize.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./style/style.css" type="text/css" rel="stylesheet" media="screen,projection">
</head>

<body data-gr-c-s-loaded="true">
  
  <!-- ********** Navigator ********** -->
  <div class="navbar-fixed">
    <nav class="maroom-box" role="navigation">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo"></a>
                                         <ul class="left hide-on-med-and-down">
                                             <li><a class="nav-item waves-effect waves-light" href="#home">Home</a></li>
                                             <li><a class="nav-item waves-effect waves-light" href="#abstract">Abstract</a></li>
                                             <li><a class="nav-item waves-effect waves-light" href="#network">Approach</a></li>
                                             <li><a class="nav-item waves-effect waves-light" href="#paper">Paper</a></li>
                                             <li><a class="nav-item waves-effect waves-light" href="#results">Results</a></li>
                                             <li><a class="nav-item waves-effect waves-light" href="#reference">References</a></li>
                                             <li><a class="nav-item waves-effect waves-light" href="#acknowledgement">Acknowledgement</a></li>
                                         </ul>

        <a href="#" data-activates="nav-mobile" class="button-collapse"><i class="material-icons">menu</i></a>
      </div>
    </nav>
  </div>
  
  <!-- ********** Title and Authors ********** -->
  <div class="section no-pad-bot" id="index-banner">
    <div class="container scrollspy" id="home">

        <h3 class="header center maroon-text">ANIM: Accurate Neural Implicit Model
for Human Reconstruction from a single RGB-D image</h3>

      <br>
      <div class="row center">
        <center>
        <h5 class="header col s2.4">
          <div class="author"><a href="https://marcopesavento.github.io/" target="blank"><font class="active-text">Marco Pesavento<sup>1,3</sup></font></a></div>
          <!--<div class="school"><a href="https://www.utk.edu/" target="blank"><font class="active-text">Centre of Vision, Speech and Signal Processing</font></a></div>-->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
       
        </h5>

        <h5 class="header col s2.4">
          <div class="author"><a href="https://web.cs.ucla.edu/~yuanluxu/" target="blank"><font class="active-text">Yuanlu Xu<sup>3</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
          
        </h5>

        <h5 class="header col s2.4">
          <div class="author"><a href="https://nsarafianos.github.io/" target="blank"><font class="active-text">Nikolaos Sarafianos<sup>3</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
        </h5>

        <h5 class="header col s2.4">
          <div class="author"><a href="https://www.rmaier.net/" target="blank"><font class="active-text">Robert Maier<sup>3</sup></font></a></div>
          <!--<div class="school"><a href="https://www.utk.edu/" target="blank"><font class="active-text">Centre of Vision, Speech and Signal Processing</font></a></div>-->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
       
        </h5>

        <h5 class="header col s2.4">
          <div class="author"><a href="https://ziyanw1.github.io/" target="blank"><font class="active-text">Ziyan Wang<sup>3</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
          
        </h5>
          </center>
        </div>
       <div class="row center">
        <h5 class="header col s2.4">
          <div class="author"><a href="https://chhankyao.github.io/" target="blank"><font class="active-text">Chun-Han Yao<sup>2,3</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
        </h5>

       

        <h5 class="header col s2.4">
          <div class="author"><a href="https://marcovolino.github.io/" target="blank"><font class="active-text">Marco Volino<sup>1</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
          
        </h5>

         <h5 class="header col s2.4">
          <div class="author"><a href="https://scholar.google.com/citations?user=bxcnXn8AAAAJ&hl=en" target="blank"><font class="active-text">Edmond Boyer<sup>3</sup></font></a></div>
          <!--<div class="school"><a href="https://www.utk.edu/" target="blank"><font class="active-text">Centre of Vision, Speech and Signal Processing</font></a></div>-->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
       
        </h5>

        <h5 class="header col s2.4 ">
          <div class="author"><a href="https://www.surrey.ac.uk/people/adrian-hilton/" target="blank"><font class="active-text">Adrian Hilton<sup>1</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
        </h5>

        <h5 class="header col s2.4">
          <div class="author"><a href="https://sites.google.com/site/tony2ng/" target="blank"><font class="active-text">Tony Tung<sup>3</sup></font></a></div>
<!--           <div class="school"><a href="https://www.surrey.ac.uk/centre-vision-speech-signal-processing/" target="blank"><font class="active-text">CVSSP</font></a></div> -->
<!--           <div class="school"><a href="https://www.surrey.ac.uk/" target="blank"><font class="active-text">University of Surrey</font></a></div> -->
        </h5>
        
        


       
       
        
      </div>
       <div class="row center">
        <h5 class="header col m4 s12">
          <div class="school"><a href="https://www.surrey.ac.uk/https://www.surrey.ac.uk/" target="blank"><font class="active-text2"><sup>1</sup>University of Surrey</font></a></div>
           </h5>
        
         <h5 class="header col m4 s12">
          <div class="school"><a href="https://www.ucmerced.edu/" target="blank"><font class="active-text2"><sup>2</sup>UC Merced</font></a></div>
           </h5>
      <h5 class="header col m4 s12">
          <div class="school"><a href="https://about.meta.com/uk/realitylabs/" target="blank"><font class="active-text2"><sup>3</sup>Meta Reality Labs</font></a></div>
           </h5>
    </div>
  </div>

  <div class="container">

      <!-- ********** Demo ********** -->
      <div class="section">

          <div class="row center">
              <div class="row">
        <div class="col m4 s12 center">
                          <img class="responsive-img" src="./first_images/bounce405.png" width="100" /><br><div align="center"><b>RGB-D input</b></div>
                      </div>
        <div class="col m4 s12 center">
                          <img class="responsive-img" src="./first_images/ours_front.png" width="200" /><br><div align="center"><b>ANIM front reconstruction </b></div>
                      </div>
        <div class="col m4 s12 center">
                          <img class="responsive-img" src="./first_images/our_back_fin.png" width="210" /><br><div align="center"><b>ANIM side reconstruction</b></div>
                      </div>
          </div>
          
      </div>

      <!-- ********** Abstract ********** -->
      <div class="row section scrollspy" id="abstract">
          <div class="title">Abstract</div><br>
Recent progress in human shape learning, shows that neural implicit models are effective in generating 3D human surfaces from limited number of views, and even from a single RGB image. 
However, existing monocular approaches still struggle to recover fine geometric details such as face, hands or cloth wrinkles. They are also easily prone to depth ambiguities that result 
in distorted geometries along the camera optical axis. In this paper, we explore the benefits of incorporating depth observations in the reconstruction process by introducing ANIM, 
a novel method that reconstructs arbitrary 3D human shapes from single-view RGB-D images with an unprecedented level of accuracy.
Our model learns geometric details from both multi-resolution pixel-aligned and voxel-aligned features to leverage depth information and enable spatial relationships, 
mitigating depth ambiguities.  We further enhance the quality of the reconstructed shape by introducing a depth-supervision strategy, 
which improves the accuracy of the signed distance field estimation of points that lie on the reconstructed surface.
Experiments demonstrate that ANIM outperforms state-of-the-art works that use RGB, surface normals, point cloud or RGB-D data as input.
In addition, we introduce ANIM-Real, a new multi-modal dataset comprising high-quality scans paired with consumer-grade RGB-D camera, and our
protocol to fine-tune \name, enabling high-quality reconstruction from real-world human capture.
      </div>

      <!-- ********** SuRS approach ********** -->
      <div class="section row scrollspy" id="network">
          <div class="title">ANIM Approach</div><br>
          <div class="row center">
              <div class="col offset-l1">&nbsp;</div>
             
                  <img class="responsive-img" src="./network/framework.png" width="100%">
           <div class="col offset-l1">&nbsp;</div>
                  
          </div>
        <figcaption>Our proposed framework has three major components: i) a multi-resolution appearance feature extractor for color and normal inputs (LR-FE and HR-FE), ii) a novel SparseConvNet U-Net 
          (Volume Feature Extractor or VFE) that efficiently extracts geometry features from 3D voxels and low-resolution image features, iii) an MLP that estimate the implicit surface representation of full-body humans. </figcaption>
        
      </div>

      

    <!-- ********** Paper ********** -->
    <div class="section row scrollspy" id="paper">
      <div class="title">Paper</div><br>
      <div class="row">
        <div class="col m6 s12 center">
          <a href="ANIM_camera_ready.pdf" target="_blank">
            <img src="./icon/icon_pdf.png">
          </a>
          <br>
          <a href="ANIM_camera_ready.pdf" target="_blank"><font class="active-text">ANIM Paper</font></a>
        </div>
        
       
        <div class="col m6 s12 center">
          <a href="" target="_blank">
            <img src="./icon/github.png">
          </a>
          <br>
          <a href="" target="_blank"><font class="active-text">ANIM-Real (coming soon)</font></a>
        </div>
       
    </div>

    <!-- ********** Citation ********** -->
    <div class="row">
      <div class="subtitle">Citation</div>
      <div class="col l10 offset-l1">
          <p>M. Pesavento, Y. Xu, N. Sarafianos, R. Maier, Z. Wang, C. Yao, M. Volino, E. Boyer, A. Hilton  and  T. Tung, "ANIM: Accurate Neural Implicit Model for Human Reconstruction from a single RGB-D image", The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</p>
      </div>
    </div>
    <div class="row">  
      <div class="subtitle">Bibtex</div>
      <div class="col l10 offset-l1">
          <pre>
@inproceedings{
}
        </pre>
      </div>
    </div>

    

    <!-- ********** Results ********** -->
    <div class="section row scrollspy" id="results">
      <div class="title">Results</div><br>
      
      <!-- ********** Quantitative evaluation ********** -->
      <div class="row">
        <div class="subtitle">Quantitative Comparisons</div><br>
        <div class="col l8 offset-l2">
          <img class="responsive-img" src="./results/quantitative.png">
          <figcaption>Quantitative comparisons with state-of-the-art approaches in 3D human reconstruction from a single input. </figcaption>
        </div>
      </div>

      <!-- ********** Qualitative evaluation ********** -->
      <div class="row">
        <div class="subtitle">Qualitative Comparisons</div><br>
        <div class="row center">
          <img class="responsive-img"  src="./results/comparisons_v3.png"  width="90%">
           <figcaption>Qualitative comparisons with state-of-the-art approaches in 3D human reconstruction from a single RGB-D data. </figcaption>
        </div>
        <div class="row center">
          <img class="responsive-img" src="./results/comparisons_v2.png"   width="90%">
           <figcaption>Qualitative comparisons with state-of-the-art approaches in 3D human reconstruction from different kinds of input. </figcaption>
        </div>
        </div>
        

      <!-- ********** Multiple references ********** -->
      <div class="row">
        <div class="subtitle">Real Data</div><br>
        <div class="col l10 offset-l1">
          <img class="responsive-img" src="./results/anim_results_supp_wb.png">
          <figcaption>Results obtained with real data from Azure-Kinect after fine-tuning ANIM with ANIM-Real </figcaption>
        
        </div>
      </div>

      


    <!-- ********** References ********** -->
    <div class="row section scrollspy" id="reference">
      <div class="title">References</div>
      <ul>
        <li> 
          <a href="https://virtualhumans.mpi-inf.mpg.de/ifnets/" target="blank">
              <font class="active-text">
                  • <b>IF-Net</b>: J. Chibane et al., "Implicit functions in feature space for 3d shape reconstruction and completion", CVPR 2020.
              </font>
          </a>
        </li>
        <li> 
          <a href="http://www.liuyebin.com/pamir/pamir.html/" target="blank">
              <font class="active-text">
                  • <b>PaMIR</b>: Z. Zheng et al., "PaMIR: Parametric Model-Conditioned Implicit Representation for Image-based Human Reconstruction", TPAMI, 2021.
              </font>
          </a>
        </li>
        <li>
          <li>
          <a href="https://github.com/facebookresearch/pifuhd/" target="blank">
              <font class="active-text">
                  • <b>PIFuHD</b>: S. Saito et al., "PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization", CVPR, 2020.
              </font>
          </a>
        </li>
        <li>
          <a href="https://icon.is.tue.mpg.de/" target="blank">
              <font class="active-text">
                  • <b>ICON</b>: Y. Xiu et al., "ICON: Implicit Clothed humans Obtained from Normals", CVPR, 2022.
              </font>
          </a>
        </li>
        <li>
          <a href="https://phorhum.github.io/" target="blank">
              <font class="active-text">
                  • <b>PHORHUM</b>: T. Alldieck et al., "Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing", CVPR, 2022.
              </font>
          </a>
        </li>
        <li>
          <a href="https://xiuyuliang.cn/econ/" target="blank">
              <font class="active-text">
                  • <b>ECON</b>: Y. Xiu et al., "ECON: Explicit Clothed humans Optimized via Normal integration", CVPR, 2023.
              </font>
          </a>
        </li>
        <li>
          <a href="https://marcopesavento.github.io/SuRS/" target="blank">
              <font class="active-text">
                  • <b>SuRS</b>: M. Pesavento et al., "Super-resolution 3D Human Shape from a Single Low-Resolution Image", ECCV, 2022.
              </font>
          </a>
        </li>
          <a href="https://shunsukesaito.github.io/PIFu/" target="blank">
              <font class="active-text">
                  • <b>PIFu</b>: S. Saito et al., “PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization”, ICCV, 2019.
              </font>
          </a>
        </li>
        
        <li> 
          <a href="https://github.com/LizhenWangT/NormalGAN/" target="blank">
              <font class="active-text">
                  • <b>NormalGAN</b>: L. Wang et al., “NormalGAN: Learning Detailed 3D Human from a Single RGB-D Image”, ECCV, 2020.
              </font>
          </a>
        </li>
        <li> 
          <a href="https://github.com/Xiaoming-Zhao/oplanes" target="blank">
              <font class="active-text">
                  • <b>OcPlane</b>: T. He et al., “Occupancy Planes for Single-view RGB-D Human Reconstruction”, AAAI, 2023.
              </font>
          </a>
        </li>
        
      </ul>
    </div>

  </div>

  <!-- ********** Acknowledgement ********** -->
    <div class="row section scrollspy" id="acknowledgement">
      <div class="title">Acknowledgement</div><br>
       This research was supported by Meta, UKRI EPSRC and BBC Prosperity Partnership AI4ME: Future Personalised Object-Based Media Experiences Delivered at Scale Anywhere EP/V038087.
      </div>
  <!-- ********** Foot ********** -->
  <footer class="page-footer grey lighten-3">
      <!-- <div class="row"> -->
<!--         <dir>

      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=n&d=nfRoOuJlwusZ4fBCJUP19LpSbhjtjv_S2GCzp2uv-Tc&cmo=3acc3a&cmn=3acc3a'></script>
        
    </dir> -->
      <!-- </div> -->
    
    <div class="footer-copyright center maroon-text">
      Copyright © Marco Pesavento 2024
    </div>
  </footer>

  <!-- ********** Script for sliding style when switching between tabs ********** -->
  <script src="./style/jquery-2.1.1.min.js"></script>
  <script src="./style/materialize.js"></script>
  <script src="./style/init.js"></script>

  

  <!-- <div class="hiddendiv common"></div><div class="drag-target" style="left: 0px; touch-action: pan-y; -webkit-user-drag: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></div><div class="jvectormap-tip"></div> -->

</body>
</html>
